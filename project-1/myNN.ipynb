{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import wandb\n",
    "from wandb.integration.keras import WandbCallback\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(\"./MIMIC_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "data_clean = data.dropna()\n",
    "y = data_clean['outcome']\n",
    "X = data_clean.drop(columns='outcome')\n",
    "\n",
    "\n",
    "X_standrd = StandardScaler()\n",
    "X_standrd = X_standrd.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_standrd, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# build input pipeline using tf.data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(BATCH_SIZE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(x_train):\n",
    "    inputs = keras.Input((x_train.shape[1],), name=\"digits\")\n",
    "    x1 = keras.layers.Dense(64, activation=\"relu\")(inputs)\n",
    "    x1 = keras.layers.Dropout(0.3)(x1)\n",
    "\n",
    "    x2 = keras.layers.Dense(64, activation=\"relu\")(x1)\n",
    "    x2 = keras.layers.Dropout(0.3)(x2)\n",
    "\n",
    "    outputs = keras.layers.Dense(10, name=\"predictions\")(x2)\n",
    "\n",
    "    return keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model = make_model(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now start to train your own model!\n",
    "\n",
    "# Design a deep neural network model tailored to our predication task of in-hospital mortality. \n",
    "# Select relevant features. \n",
    "# Your model should include a combination of dense  layers and activation functions optimized for binary classification. \n",
    "# Try to play with the  optimizer, loss, etc.\n",
    "\n",
    "# 3 construct DNN\n",
    "\n",
    "\n",
    "\n",
    "# 4 Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, validation_split=0.2, verbose=1)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_accuracy(history)\n",
    "plot_loss(history)\n",
    "plt.show()\n",
    "\n",
    "eval_ = model.evaluate(X_test, y_test, verbose=1)[1]\n",
    "print(eval_)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
